{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import sklearn.neural_network as sk_nn\n",
    "import sklearn.tree as sk_tree\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict_long = { # We want to make colorless its own color. This labelling system makes all color combos distinct, which will be more difficult for the classifier\n",
    "    (): 0, # Colorless\n",
    "    (\"W\",): 1, # White\n",
    "    (\"U\",): 2, # Blue\n",
    "    (\"B\",): 3, # Black\n",
    "    (\"R\",): 4, # Red\n",
    "    (\"G\",): 5, # Green\n",
    "    (\"G\", \"W\"): 6, # Selesnya\n",
    "    (\"U\", \"W\"): 7, # Azorius\n",
    "    (\"B\", \"U\"): 8, # Dimir\n",
    "    (\"B\", \"R\"): 9, # Rakdos\n",
    "    (\"G\", \"R\"): 10, # Gruul\n",
    "    (\"B\", \"G\"): 11, # Golgari\n",
    "    (\"B\", \"W\"): 12, # Orzhov\n",
    "    (\"G\", \"U\"): 13, # Simic\n",
    "    (\"R\", \"U\"): 14, # Izzet\n",
    "    (\"R\", \"W\"): 15, # Boros\n",
    "    (\"B\", \"G\", \"R\"): 16,  # Jund\n",
    "    (\"B\", \"G\", \"U\"): 17,  # Sultai\n",
    "    (\"B\", \"G\", \"W\"): 18,  # Abzan\n",
    "    (\"B\", \"R\", \"U\"): 19,  # Grixis\n",
    "    (\"B\", \"R\", \"W\"): 20,  # Mardu\n",
    "    (\"B\", \"U\", \"W\"): 21,  # Esper\n",
    "    (\"G\", \"R\", \"U\"): 22,  # Temur\n",
    "    (\"G\", \"R\", \"W\"): 23,  # Naya\n",
    "    (\"G\", \"U\", \"W\"): 24,  # Bant\n",
    "    (\"R\", \"U\", \"W\"): 25,  # Jeskai\n",
    "    (\"B\", \"G\", \"R\", \"U\"): 26, # Whiteless (Yidris)\n",
    "    (\"B\", \"G\", \"R\", \"W\"): 27, # Blueless (Saskia)\n",
    "    (\"B\", \"G\", \"U\", \"W\"): 28, # Redless (Atraxa)\n",
    "    (\"B\", \"R\", \"U\", \"W\"): 29, # Greenless (Breya)\n",
    "    (\"G\", \"R\", \"U\", \"W\"): 30, # Blackless (Aragorn)\n",
    "    (\"B\", \"G\", \"R\", \"U\", \"W\"): 31 # 5-Color\n",
    "}\n",
    "\n",
    "color_dict_short = {\n",
    "    \"\": 0, # Colorless\n",
    "    \"W\": 1, # White\n",
    "    \"U\": 2, # Blue\n",
    "    \"B\": 3, # Black\n",
    "    \"R\": 4, # Red\n",
    "    \"G\": 5, # Green\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./common_types.txt\", \"rb\") as f:\n",
    "       common_types = pickle.load(f)\n",
    "\n",
    "cols_include_all = ['colorIdentity', 'colors', 'firstPrinting', 'keywords', 'manaCost', 'manaValue',\n",
    "                     'subtypes', 'supertypes', 'text', 'type', 'types', 'power', 'toughness',  'colorIndicator',\n",
    "                     'name', 'hasAlternativeDeckLimit']\n",
    "cols_include_noncreature = ['loyalty',]\n",
    "cols_edhrec = [\"edhrecRank\", \"edhrecSaltiness\"]\n",
    "cols_legality = ['legalities.commander', 'legalities.duel', 'legalities.explorer',\n",
    "       'legalities.historic', 'legalities.historicbrawl', 'legalities.legacy',\n",
    "       'legalities.modern', 'legalities.oathbreaker', 'legalities.pauper',\n",
    "       'legalities.paupercommander', 'legalities.penny', 'legalities.pioneer',\n",
    "       'legalities.vintage', 'legalities.gladiator','legalities.alchemy',\n",
    "       'legalities.brawl', 'legalities.future', 'legalities.standard', 'legalities.predh',\n",
    "       'legalities.premodern', 'legalities.oldschool',]\n",
    "cols_leadership = ['leadershipSkills.brawl',\n",
    "       'leadershipSkills.commander', 'leadershipSkills.oathbreaker',]\n",
    "\n",
    "def to_feature_name(s: str, typ: bool = False) -> str:\n",
    "    if typ:\n",
    "        return \"f_ct_\" + s.lower().replace(\" \", \"_\")\n",
    "    return \"f_kw_\" + s.lower().replace(\" \", \"_\")\n",
    "\n",
    "def get_kw_list(filename: str):\n",
    "    \"\"\"Get list of keywords from file\"\"\"\n",
    "    with open(filename+\".json\") as f:\n",
    "        json_data = json.load(f)\n",
    "    data = json_data[\"data\"]\n",
    "    ability_words = data[\"abilityWords\"]\n",
    "    kw_abilities = data[\"keywordAbilities\"]\n",
    "    kw_actions = data[\"keywordActions\"]\n",
    "    all_kws = ability_words + kw_abilities + kw_actions\n",
    "    return all_kws, ability_words, kw_abilities, kw_actions\n",
    "\n",
    "def make_types_list(df: pd.DataFrame, n: int) -> None:\n",
    "    \"\"\"From a complete dataset, write a list of the 200 most common creature types to a file called common_types.txt\"\"\"\n",
    "    all_types = []\n",
    "    df[\"subtypes\"].apply(all_types.extend)\n",
    "    all_types = Counter(all_types)\n",
    "    common_types = [x for x,y in all_types.most_common(n)]\n",
    "    with open(\"./common_types.txt\", \"wb\") as f:\n",
    "        pickle.dump(common_types, f)\n",
    "\n",
    "# make_types_list(df, 50)\n",
    "\n",
    "# all_kws, _, _, _ = get_kw_list(\"../data/mtg/Keywords\")\n",
    "all_kws, _, _, _ = get_kw_list(\"./short_keywords\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WDAmo\\AppData\\Local\\Temp\\ipykernel_12828\\1392033885.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature] = df[\"subtypes\"].apply(lambda x: 1 if typ in x else 0)\n",
      "C:\\Users\\WDAmo\\AppData\\Local\\Temp\\ipykernel_12828\\1392033885.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature] = df[\"subtypes\"].apply(lambda x: 1 if typ in x else 0)\n"
     ]
    }
   ],
   "source": [
    "def load_atomic(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Load from the Atomic standard files into a dataframe resembling the old data standard.\"\"\"\n",
    "    with open(\"../data/mtg/\"+filename+\".json\") as f:\n",
    "        json_data = json.load(f)  # Load from file\n",
    "    json_data = json_data[\"data\"]\n",
    "    cards = [x[0] for x in json_data.values() if len(x) == 1] # Pull only cards with 1 face (no transform, fuse, split, flip cards, sorry Delver)\n",
    "    df = pd.json_normalize(cards)\n",
    "    return df\n",
    "\n",
    "def prep_df(df: pd.DataFrame, monocolor: bool, creatures: bool, modern: bool, small: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocesses card DF\n",
    "    @param df: Input DataFrame\n",
    "    @param monocolor: If true, return only cards with 1 or less color\n",
    "    @param creatures: If true, return only creatures\n",
    "    @param modern: If true, filter by modern legality (excludes Uro :'( )\n",
    "    \"\"\"\n",
    "    df[\"num_colors\"] = df[\"colorIdentity\"].map(len)\n",
    "    if creatures:\n",
    "        df = df.loc[df['type'].str.contains('Creature')]\n",
    "    if monocolor:\n",
    "        df = df.loc[df['num_colors'] <= 1]\n",
    "    if modern:\n",
    "        df = df.loc[df[\"legalities.modern\"] == \"Legal\"]\n",
    "    df = df[cols_include_all]\n",
    "    df[\"f_is_artifact\"] = df[\"supertypes\"].apply(lambda x: 1 if \"Artifact\" in x else 0)\n",
    "    df[\"f_is_enchantment\"] = df[\"supertypes\"].apply(lambda x: 1 if \"Enchantment\" in x else 0)\n",
    "    df[\"f_cmc\"] = (df[\"manaValue\"] / 7.5) - 1  # [0,15] -> [-1, 1]\n",
    "    df['f_pow'] = df['power'].replace({\"1+*\": 1, \"*\": \"0\", \"*+1\": 1}) # Assume all *'s are 0 (as per the rules)\n",
    "    df['f_pow'] = ((df['f_pow'].astype(int) + 1) / 9) - 1 # [-1,16] -> [-1, 1]\n",
    "    df['f_tough'] = df['toughness'].replace({\"1+*\": 1, \"*\": \"0\", \"*+1\": 1}) # Assume all *'s are 0 (as per the rules)\n",
    "    df['f_tough'] = ((df['f_tough'].astype(int) + 1) / 9) - 1 # [-1,16] -> [-1, 1]\n",
    "\n",
    "    df[\"label_identity\"] = df[\"colorIdentity\"].apply(lambda x: color_dict_long[tuple(x)]) # Could use 'colors' instead, but Kenrith should be classified as a 5C card, and Tasigur as Sultai.\n",
    "    df[\"label_white\"] = df[\"colorIdentity\"].apply(lambda x: 1 if \"W\" in x else 0)\n",
    "    df[\"label_blue\"] = df[\"colorIdentity\"].apply(lambda x: 1 if \"U\" in x else 0)\n",
    "    df[\"label_black\"] = df[\"colorIdentity\"].apply(lambda x: 1 if \"B\" in x else 0)\n",
    "    df[\"label_red\"] = df[\"colorIdentity\"].apply(lambda x: 1 if \"R\" in x else 0)\n",
    "    df[\"label_green\"] = df[\"colorIdentity\"].apply(lambda x: 1 if \"G\" in x else 0)\n",
    "    df[\"label_colorless\"] = df[\"colorIdentity\"].apply(lambda x: 1 if len(x) == 0 else 0)\n",
    "\n",
    "    # Binary columns for types and keywords\n",
    "    for kw in all_kws:\n",
    "        feature = to_feature_name(kw)\n",
    "        df[feature] = df[\"text\"].str.contains(kw, case=False, na=0).astype(int)  # This works, but Death's Shadow counts as a creature with Shadow. Could look into using reminder text?\n",
    "    for typ in common_types:\n",
    "        feature = to_feature_name(typ, True)\n",
    "        df[feature] = df[\"subtypes\"].apply(lambda x: 1 if typ in x else 0)\n",
    "    df = df.set_index(\"name\")\n",
    "    return df\n",
    "\n",
    "df = prep_df(load_atomic(\"ModernAtomic\"), monocolor=True, creatures=True, modern=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Preprocessing\n",
    "\n",
    "features = [x for x in list(df.columns) if x.startswith(\"f_\")]\n",
    "labels = [x for x in list(df.columns) if x.startswith(\"label_\")]\n",
    "\n",
    "ml_df = df[features + labels]\n",
    "\n",
    "sk_scaler = sk.preprocessing.StandardScaler().fit(ml_df)\n",
    "\n",
    "train, test = sk.model_selection.train_test_split(ml_df, test_size = 0.15)\n",
    "train_features, train_labels = train[features], train[labels]\n",
    "test_features, test_labels = test[features], test[labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.79947357\n",
      "Iteration 2, loss = 1.79372601\n",
      "Iteration 3, loss = 1.78804907\n",
      "Iteration 4, loss = 1.78333189\n",
      "Iteration 5, loss = 1.77921896\n",
      "Iteration 6, loss = 1.77542920\n",
      "Iteration 7, loss = 1.77216664\n",
      "Iteration 8, loss = 1.76909050\n",
      "Iteration 9, loss = 1.76634313\n",
      "Iteration 10, loss = 1.76380152\n",
      "Iteration 11, loss = 1.76140850\n",
      "Iteration 12, loss = 1.75918918\n",
      "Iteration 13, loss = 1.75717101\n",
      "Iteration 14, loss = 1.75552121\n",
      "Iteration 15, loss = 1.75399338\n",
      "Iteration 16, loss = 1.75253265\n",
      "Iteration 17, loss = 1.75116176\n",
      "Iteration 18, loss = 1.74987166\n",
      "Iteration 19, loss = 1.74869793\n",
      "Iteration 20, loss = 1.74775343\n",
      "Iteration 21, loss = 1.74671670\n",
      "Iteration 22, loss = 1.74583379\n",
      "Iteration 23, loss = 1.74500564\n",
      "Iteration 24, loss = 1.74434854\n",
      "Iteration 25, loss = 1.74378105\n",
      "Iteration 26, loss = 1.74315970\n",
      "Iteration 27, loss = 1.74260566\n",
      "Iteration 28, loss = 1.74207702\n",
      "Iteration 29, loss = 1.74164854\n",
      "Iteration 30, loss = 1.74121297\n",
      "Iteration 31, loss = 1.74076728\n",
      "Iteration 32, loss = 1.74041558\n",
      "Iteration 33, loss = 1.74004320\n",
      "Iteration 34, loss = 1.73971889\n",
      "Iteration 35, loss = 1.73939476\n",
      "Iteration 36, loss = 1.73908831\n",
      "Iteration 37, loss = 1.73882197\n",
      "Iteration 38, loss = 1.73858327\n",
      "Iteration 39, loss = 1.73833886\n",
      "Iteration 40, loss = 1.73814891\n",
      "Iteration 41, loss = 1.73793009\n",
      "Iteration 42, loss = 1.73776701\n",
      "Iteration 43, loss = 1.73759811\n",
      "Iteration 44, loss = 1.73740611\n",
      "Iteration 45, loss = 1.73722266\n",
      "Iteration 46, loss = 1.73709613\n",
      "Iteration 47, loss = 1.73693579\n",
      "Iteration 48, loss = 1.73680738\n",
      "Iteration 49, loss = 1.73668625\n",
      "Iteration 50, loss = 1.73656169\n",
      "Iteration 51, loss = 1.73646936\n",
      "Iteration 52, loss = 1.73633593\n",
      "Iteration 53, loss = 1.73625008\n",
      "Iteration 54, loss = 1.73611971\n",
      "Iteration 55, loss = 1.73601172\n",
      "Iteration 56, loss = 1.73590252\n",
      "Iteration 57, loss = 1.73584588\n",
      "Iteration 58, loss = 1.73579340\n",
      "Iteration 59, loss = 1.73569827\n",
      "Iteration 60, loss = 1.73560927\n",
      "Iteration 61, loss = 1.73555443\n",
      "Iteration 62, loss = 1.73549569\n",
      "Iteration 63, loss = 1.73545933\n",
      "Iteration 64, loss = 1.73537227\n",
      "Iteration 65, loss = 1.73528693\n",
      "Iteration 66, loss = 1.73521670\n",
      "Iteration 67, loss = 1.73515255\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(10, 6), max_iter=20000, solver=&#x27;sgd&#x27;,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(10, 6), max_iter=20000, solver=&#x27;sgd&#x27;,\n",
       "              verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10, 6), max_iter=20000, solver='sgd',\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SKLearn MLP on mono-colored creatures\n",
    "sk_clf = sk_nn.MLPClassifier(solver='sgd', hidden_layer_sizes=(10, 6), max_iter = 20000, verbose= True)\n",
    "\n",
    "sk_clf.fit(train_features, train_labels[\"label_identity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20308483290488433"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_clf.score(test_features, test_labels[\"label_identity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN GOAL: Determine a creature's color identity based on: (number of features)\n",
    "- CMC (1)\n",
    "- Power (1)\n",
    "- Toughness (1)\n",
    "- Artifact / Enchantment Supertype (2)\n",
    "- Type (boolean cols for each of the top 200 tribes) (200)\n",
    "- Keywords (see keywords.json and list of evergreen keywords on https://mtg.fandom.com/wiki/Evergreen) (20-200)\n",
    "- Name? (Would need a way to break this down (https://web.stanford.edu/group/pdplab/pdphandbook/handbookch8.html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "evergreen_keywords = [\"Activate\", \"Attach\", \"Cast\", \"Counter\", \"Create\", \"Destroy\", \"Discard\", \"Exchange\", \"Exile\", \"Fight\",\n",
    "                       \"Mill\", \"Play\", \"Reveal\", \"Sacrifice\", \"Scry\", \"Search\", \"Shuffle\", \"Tap\", \"Untap\"]\n",
    "my_common_words = [\"Enchantment\", \"Artifact\", \"+1/+1\", \"Token\", \"Draw\" \"Land\", \"Nonland\", \"Spell\", \"Creature\",]\n",
    "evergreen_abilities = [\"Deathtouch\", \"Defender\", \"Double Strike\", \"Enchant\", \"Equip\", \"First Strike\", \"Flash\", \"Flying\",\n",
    "                        \"Haste\", \"Hexproof\", \"Indestructible\", \"Lifelink\", \"Menace\", \"Protection\", \"Reach\", \"Trample\",\n",
    "                          \"Vigilance\", \"Ward\", \"Regenerate\", \"Shroud\", \"Intimidate\", \"Prowess\"]\n",
    "all_keywords = evergreen_keywords + my_common_words + evergreen_abilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue #1: Multi-faced cards from the Atomic dataset.\n",
    "The more robust atmoic dataset contains split entries for DFC's, fuse cards, etc. How do we count these cards?\n",
    "A. Remove them from the dataset.\n",
    "    # By far the easiest approach.\n",
    "B. Look at just the front.\n",
    "    # Cleanest, will cause some outliers, namely on meld/fuse/transform cards\n",
    "C. Add them as an additional row.\n",
    "    # More accurate, but will likely be outliers\n",
    "D. Add extra columns\n",
    "    # Most accurate, but will mess with any ML algo if not weighted properly.\n",
    "\n",
    "# Issue #2: Keywords Overlap with Creature Names (Death's Shadow, Flying Men)\n",
    "This is mostly fine. For one thing, many of these cards match color identity with their mechanic (Flying men are blue, DS is black, etc.)\n",
    "We could look into some kind of way to differentiate based on regex or pattern matching, but let's leave that for now.   \n",
    "\n",
    "# Issue 3: The word Counter\n",
    "So, despite being able to name things whatever they want, and repeated oracle changes to simplify and clarify wording, MTG still uses the word 'counter' to mean two different things: a keyword action meaning \"Remove this spell or ability from the stack\", and a board object placed on permanents i.e. +1/+1 counters, loyalty counters. Countering things (first interpretation) is a blue-coded mechanic, while counters (second interpretation) are a fairly universal mechanic, maybe leaning white and green but with no real identity. Again, we could look into differentiating these by string matching (\"counter target\" vs \"+1/+1 counter\"), but since counters don't really have an identity, we're changing \"counter\" in keyword abilities to \"counter target\". There are also way too many strings about the other kind of counter to simply process (counter vs counters, etc.). This does remove Baral, the bluest creature ever, from the counter keyword column, but whatever.\n",
    "\n",
    "# Issue 4: Parsing Card Names\n",
    "This might be an entirely different ML task. There are packages to determine semantic vectors of words. Use the names of each card (sum of all word vectors) as a feature set. A card like Death's Shadow would be easy peasy. Brushwagg, on the other hand, maybe not. Proper names like Olivia Voldaren, or worse, Drizz't Dourden, would be all but impossible.\n",
    "\n",
    "# Issue 5: Improving Performance\n",
    "Current accuracy for testing dataset sits at about 64%- not great for a binary classifier, but pretty good for a classifier with 6 classes (chance rate of 17%). Let's try running a binary classifier on enemy-colors cards, say blue and green (probably the most disparate colors in terms of creatures).\n",
    "\n",
    "# Issue 6: PCA\n",
    "PCA didn't improve the performance of the neural net, as expected (59.1% w/ PCA and 64% without). It also reduced performance on the decision tree (45%  with and 54% without). This makes sense, since we lose information with PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68844145\n",
      "Iteration 2, loss = 0.68782144\n",
      "Iteration 3, loss = 0.68724528\n",
      "Iteration 4, loss = 0.68658266\n",
      "Iteration 5, loss = 0.68610602\n",
      "Iteration 6, loss = 0.68576749\n",
      "Iteration 7, loss = 0.68549381\n",
      "Iteration 8, loss = 0.68528961\n",
      "Iteration 9, loss = 0.68513522\n",
      "Iteration 10, loss = 0.68499342\n",
      "Iteration 11, loss = 0.68490886\n",
      "Iteration 12, loss = 0.68480974\n",
      "Iteration 13, loss = 0.68477507\n",
      "Iteration 14, loss = 0.68473257\n",
      "Iteration 15, loss = 0.68464794\n",
      "Iteration 16, loss = 0.68458985\n",
      "Iteration 17, loss = 0.68453594\n",
      "Iteration 18, loss = 0.68448767\n",
      "Iteration 19, loss = 0.68444375\n",
      "Iteration 20, loss = 0.68439648\n",
      "Iteration 21, loss = 0.68435626\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(10, 6), max_iter=10000, solver=&#x27;sgd&#x27;,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(10, 6), max_iter=10000, solver=&#x27;sgd&#x27;,\n",
       "              verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10, 6), max_iter=10000, solver='sgd',\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simic_df = df.loc[df[\"colorIdentity\"].isin([[\"G\"], [\"U\"]])]\n",
    "simic_df.head(10)\n",
    "\n",
    "# SKLearn MLP on U and G creatures\n",
    "sk_clf = sk_nn.MLPClassifier(solver='sgd', hidden_layer_sizes=(10, 6), max_iter = 10000, verbose= True)\n",
    "\n",
    "features = [x for x in list(simic_df.columns) if x.startswith(\"f_\")]\n",
    "labels = [x for x in list(simic_df.columns) if x.startswith(\"label_\")]\n",
    "\n",
    "ml_df = simic_df[features + labels]\n",
    "\n",
    "sk_scaler = sk.preprocessing.StandardScaler().fit(ml_df)\n",
    "\n",
    "train, test = sk.model_selection.train_test_split(ml_df, test_size = 0.15)\n",
    "train_features, train_labels = train[features], train[labels]\n",
    "test_features, test_labels = test[features], test[labels]\n",
    "\n",
    "sk_clf.fit(train_features, train_labels[\"label_identity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5242494226327945"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_clf.score(test_features, test_labels[\"label_identity\"])\n",
    "\n",
    "# Hell yeah, brother. 85% on a binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = sk_tree.DecisionTreeClassifier()\n",
    "tree_clf.fit(train_features, train_labels[\"label_identity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>Inexorable Blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f_is_artifact</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_is_enchantment</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_cmc</th>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_pow</th>\n",
       "      <td>-0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_tough</th>\n",
       "      <td>-0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name              Inexorable Blob\n",
       "f_is_artifact            0.000000\n",
       "f_is_enchantment         0.000000\n",
       "f_cmc                   -0.600000\n",
       "f_pow                   -0.555556\n",
       "f_tough                 -0.555556"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.sample(1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2639245929734362"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.score(test_features, test_labels[\"label_identity\"])\n",
    "\n",
    "# 54.5% accuracy on a tree. Worse than a neural net. I worry the massive amount of type and keyword columns is messing with it.\n",
    "# Removing types and keywords leaves us with 26% accuracy. Not good, but better than neural net with this shrunk feature space (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I forgot about dimensionality reduction!\n",
    "# Let's do some basic-ass PCA on the larger dataset.\n",
    "\n",
    "\n",
    "pca = PCA(n_components = 25)\n",
    "pca_df = pd.DataFrame(pca.fit_transform(df[features]))\n",
    "pca_df.index = df.index\n",
    "pca_df[\"label_identity\"] = df[\"label_identity\"]\n",
    "\n",
    "train, test = sk.model_selection.train_test_split(pca_df, test_size = 0.15)\n",
    "train_features, train_labels = train[range(0,25)], train[\"label_identity\"]\n",
    "test_features, test_labels = test[range(0,25)], test[\"label_identity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46358183376178236"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SKLearn MLP on mono-colored creatures\n",
    "sk_clf = sk_tree.DecisionTreeClassifier()\n",
    "\n",
    "sk_clf.fit(train_features, train_labels)\n",
    "\n",
    "sk_clf.score(test_features, test_labels)\n",
    "\n",
    "# 59% accuracy after PCA.\n",
    "\n",
    "\n",
    "# Next time: Random forest decision tree, then exploring the best tree to find insights into the color pie\n",
    "# Also next time: using larger and smaller datasets (AtomicCards, LegacyAtomic, StandardAtomic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
