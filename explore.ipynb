{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./common_types.txt\", \"rb\") as f:\n",
    "       common_types = pickle.load(f)\n",
    "\n",
    "cols_include_all = ['colorIdentity', 'colors', 'firstPrinting', 'keywords', 'manaCost', 'manaValue',\n",
    "                     'subtypes', 'supertypes', 'text', 'type', 'types', 'power', 'toughness',  'colorIndicator',\n",
    "                     'asciiName', 'hasAlternativeDeckLimit']\n",
    "cols_include_noncreature = ['loyalty',]\n",
    "cols_edhrec = [\"edhrecRank\", \"edhrecSaltiness\"]\n",
    "cols_legality = ['legalities.commander', 'legalities.duel', 'legalities.explorer',\n",
    "       'legalities.historic', 'legalities.historicbrawl', 'legalities.legacy',\n",
    "       'legalities.modern', 'legalities.oathbreaker', 'legalities.pauper',\n",
    "       'legalities.paupercommander', 'legalities.penny', 'legalities.pioneer',\n",
    "       'legalities.vintage', 'legalities.gladiator','legalities.alchemy',\n",
    "       'legalities.brawl', 'legalities.future', 'legalities.standard', 'legalities.predh',\n",
    "       'legalities.premodern', 'legalities.oldschool',]\n",
    "cols_leadership = ['leadershipSkills.brawl',\n",
    "       'leadershipSkills.commander', 'leadershipSkills.oathbreaker',]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_atomic(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Load from the Atomic standard files into a dataframe resembling the old data standard.\"\"\"\n",
    "    with open(\"../data/mtg/\"+filename+\".json\") as f:\n",
    "        json_data = json.load(f)  # Load from file\n",
    "    json_data = json_data[\"data\"]\n",
    "    cards = [x[0] for x in json_data.values() if len(x) == 1] # Pull only cards with 1 face (no transform, fuse, split, flip cards, sorry Delver)\n",
    "    df = pd.json_normalize(cards)\n",
    "    return df\n",
    "\n",
    "def prep_df(df: pd.DataFrame, monocolor: bool, creatures: bool, modern: bool) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocesses card DF\n",
    "    @param df: Input DataFrame\n",
    "    @param monocolor: If true, return only cards with 1 or less color\n",
    "    @param creatures: If true, return only creatures\n",
    "    @param modern: If true, filter by modern legality (excludes Uro, :'( )\n",
    "    \"\"\"\n",
    "    df.set_index(\"asciiName\")\n",
    "    df[\"num_colors\"] = df[\"colors\"].map(len)\n",
    "    if creatures:\n",
    "        df = df.loc[df['type'].str.contains('Creature')]\n",
    "    if monocolor:\n",
    "        df = df.loc[df['num_colors'] <= 1]\n",
    "    if modern:\n",
    "        df = df.loc[df[\"legalities.modern\"] == \"Legal\"]\n",
    "    df[\"f_cmc\"] = (df[\"manaValue\"] / 7.5) - 1  # [0,15] -> [-1, 1]\n",
    "    df['f_pow'] = df['power'].replace({\"1+*\": 1, \"*\": \"0\", \"*+1\": 1}) # Assume all *'s are 0 (as per the rules)\n",
    "    df['f_pow'] = ((df['f_pow'].astype(int) + 1) / 9) - 1 # [-1,16] -> [-1, 1]\n",
    "    df['f_tough'] = df['toughness'].replace({\"1+*\": 1, \"*\": \"0\", \"*+1\": 1}) # Assume all *'s are 0 (as per the rules)\n",
    "    df['f_tough'] = ((df['f_tough'].astype(int) + 1) / 9) - 1 # [-1,16] -> [-1, 1]\n",
    "    df = df[cols_include_all]\n",
    "    return df\n",
    "\n",
    "df = prep_df(load_atomic(\"ModernAtomic\"), monocolor=False, creatures=True, modern=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m./common_types.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      8\u001b[0m         f\u001b[39m.\u001b[39mwrite(json\u001b[39m.\u001b[39mdumps(common_types))\n\u001b[1;32m---> 10\u001b[0m make_types_list(df)\n",
      "Cell \u001b[1;32mIn[89], line 8\u001b[0m, in \u001b[0;36mmake_types_list\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      6\u001b[0m common_types \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m all_types\u001b[39m.\u001b[39mmost_common(\u001b[39m200\u001b[39m)]\n\u001b[0;32m      7\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m./common_types.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> 8\u001b[0m     f\u001b[39m.\u001b[39;49mwrite(json\u001b[39m.\u001b[39;49mdumps(common_types))\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "def make_types_list(df: pd.DataFrame) -> None:\n",
    "    \"\"\"From a complete dataset, write a list of the 200 most common creature types to a file called common_types.txt\"\"\"\n",
    "    all_types = []\n",
    "    df[\"subtypes\"].apply(all_types.extend)\n",
    "    all_types = Counter(all_types)\n",
    "    common_types = [x.lower() for x,y in all_types.most_common(200)]\n",
    "    with open(\"./common_types.txt\", \"wb\") as f:\n",
    "        pickle.dump(common_types, f)\n",
    "\n",
    "make_types_list(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7380            Invoke Despair\n",
       "11563      Reckoner Bankbuster\n",
       "14976    The Meathook Massacre\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_feature_name(s: str) -> str:\n",
    "    return \"f_\" + s.lower().replace(\" \", \"_\")\n",
    "\n",
    "def get_kw_list(filename: str):\n",
    "    \"\"\"Get list of keywords from file\"\"\"\n",
    "    with open(\"../data/mtg/\"+filename+\".json\") as f:\n",
    "        json_data = json.load(f)\n",
    "    data = json_data[\"data\"]\n",
    "    ability_words = data[\"abilityWords\"]\n",
    "    kw_abilities = data[\"keywordAbilities\"]\n",
    "    kw_actions = data[\"keywordActions\"]\n",
    "    all_kws = ability_words + kw_abilities + kw_actions\n",
    "    return all_kws, ability_words, kw_abilities, kw_actions\n",
    "\n",
    "all_type_labels = Counter([x for l in df['subtypes'] for x in l]) # We need to define this globally. Let's do it.\n",
    "most_common_types = [x for x, y in all_type_labels.most_common(100)]\n",
    "\n",
    "a,b,c,d = get_kw_list(\"Keywords\")\n",
    "a # 297 total keywords. Some terms (Counter being the big one) are ambiguous, while others can appear on card names (Assemble -> Assemble the Legion).\n",
    "  # We can reduce the noise here by manually removing irrelevant keywords, but let's leave them for now.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "descriptor 'lower' for 'str' objects doesn't apply to a 'list' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[39m=\u001b[39m mono_creatures\n\u001b[1;32m----> 2\u001b[0m df\u001b[39m.\u001b[39;49mapplymap(\u001b[39mstr\u001b[39;49m\u001b[39m.\u001b[39;49mlower)\n\u001b[0;32m      3\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mf_cmc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (df[\u001b[39m\"\u001b[39m\u001b[39mconvertedManaCost\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m/\u001b[39m \u001b[39m7.5\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\WDAmo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9653\u001b[0m, in \u001b[0;36mDataFrame.applymap\u001b[1;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[0;32m   9650\u001b[0m         \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer(x, func, ignore_na\u001b[39m=\u001b[39mignore_na)\n\u001b[0;32m   9651\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer(x\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values, func, ignore_na\u001b[39m=\u001b[39mignore_na)\n\u001b[1;32m-> 9653\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(infer)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mapplymap\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\WDAmo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\WDAmo\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\WDAmo\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\WDAmo\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\WDAmo\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9651\u001b[0m, in \u001b[0;36mDataFrame.applymap.<locals>.infer\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   9649\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mempty:\n\u001b[0;32m   9650\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer(x, func, ignore_na\u001b[39m=\u001b[39mignore_na)\n\u001b[1;32m-> 9651\u001b[0m \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(x\u001b[39m.\u001b[39;49mastype(\u001b[39mobject\u001b[39;49m)\u001b[39m.\u001b[39;49m_values, func, ignore_na\u001b[39m=\u001b[39;49mignore_na)\n",
      "File \u001b[1;32mc:\\Users\\WDAmo\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: descriptor 'lower' for 'str' objects doesn't apply to a 'list' object"
     ]
    }
   ],
   "source": [
    "df = mono_creatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"subtypes\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Abattoir Ghoul        NaN\n",
       "Abbey Griffin         NaN\n",
       "Abbot of Keral Keep   NaN\n",
       "Aberrant Researcher   NaN\n",
       "Abhorrent Overlord    NaN\n",
       "                       ..\n",
       "Zombie Musher         NaN\n",
       "Zulaport Chainmage    NaN\n",
       "Zulaport Cutthroat    NaN\n",
       "Zulaport Enforcer     NaN\n",
       "Zurgo Bellstriker     NaN\n",
       "Name: subtypes, Length: 6346, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"subtypes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'most_common_types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m most_common_types:\n\u001b[0;32m      2\u001b[0m     c_name \u001b[39m=\u001b[39m to_feature_name(\u001b[39m\"\u001b[39m\u001b[39mct_\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mc)\n\u001b[0;32m      3\u001b[0m     df[c_name] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[df[\u001b[39m\"\u001b[39m\u001b[39mtypes\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(c)]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'most_common_types' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for c in most_common_types:\n",
    "    c_name = to_feature_name(\"ct_\"+c)\n",
    "    df[c_name] = df.loc[df[\"types\"].str.contains(c)]\n",
    "\n",
    "for c in all_keywords:\n",
    "    c_name = to_feature_name(\"ct_\"+c)\n",
    "    df[c_name] = df.loc[df[\"text\"].str.contains(c)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN GOAL: Determine a creature's color identity based on: (number of features)\n",
    "- CMC (1)\n",
    "- Power (1)\n",
    "- Toughness (1)\n",
    "- Type (boolean cols for each of the top 100 tribes) (100)\n",
    "- Keywords (see keywords.json and list of evergreen keywords on https://mtg.fandom.com/wiki/Evergreen) (20-100)\n",
    "- Name? (Would need a way to break this down (https://web.stanford.edu/group/pdplab/pdphandbook/handbookch8.html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "evergreen_keywords = [\"Activate\", \"Attach\", \"Cast\", \"Counter\", \"Create\", \"Destroy\", \"Discard\", \"Exchange\", \"Exile\", \"Fight\",\n",
    "                       \"Mill\", \"Play\", \"Reveal\", \"Sacrifice\", \"Scry\", \"Search\", \"Shuffle\", \"Tap\", \"Untap\"]\n",
    "my_common_words = [\"Enchantment\", \"Artifact\", \"+1/+1\", \"Token\", \"Draw\" \"Land\", \"Nonland\", \"Spell\", \"Creature\",]\n",
    "evergreen_abilities = [\"Deathtouch\", \"Defender\", \"Double Strike\", \"Enchant\", \"Equip\", \"First Strike\", \"Flash\", \"Flying\",\n",
    "                        \"Haste\", \"Hexproof\", \"Indestructible\", \"Lifelink\", \"Menace\", \"Protection\", \"Reach\", \"Trample\",\n",
    "                          \"Vigilance\", \"Ward\", \"Regenerate\", \"Shroud\", \"Intimidate\", \"Prowess\"]\n",
    "all_keywords = evergreen_keywords + my_common_words + evergreen_abilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The more robust atmoic dataset contains split entries for DFC's, fuse cards, etc. How do we count these cards?\n",
    "A. Remove them from the dataset.\n",
    "    # By far the easiest approach.\n",
    "B. Look at just the front.\n",
    "    # Cleanest, will cause some outliers, namely on meld/fuse/transform cards\n",
    "C. Add them as an additional row.\n",
    "    # More accurate, but will likely be outliers\n",
    "D. Add extra columns\n",
    "    # Most accurate, but will mess with any ML algo if not weighted properly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
